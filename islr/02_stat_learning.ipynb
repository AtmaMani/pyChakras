{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chap 2: Start Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "In a prediction / regression problem, the inputs (denoted by `X`) are called as `predictors`, `independent variables`, `features` and the predicted variable is called as `response`, `dependent variable` and is denoted by `Y`.\n",
    "\n",
    "The relationship betwen input and predicted is represented as\n",
    "\n",
    "$$\n",
    "Y = f(X) + \\epsilon\n",
    "$$\n",
    "\n",
    "where $f$ is some fixed, unknown function that is to be determined. $\\epsilon$ is **random error** term that is independent of `X` and has **zero mean**.\n",
    "\n",
    "In reality, $f$ may depend on more than 1 input variable $X$, for instance 2. In this case, $f$ is a `2D` surface that is fit. In general, the process of **estimating** $f$ is **statistical learning**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducible and Irreducible errors\n",
    "Since $f$ and $Y$ cannot be **calculated**, the best we can get is to **estimate** them. Thus, the estimates are called $\\hat f$ and $\\hat Y$\n",
    "\n",
    "$$\n",
    "\\hat Y = \\hat f(X)\n",
    "$$\n",
    "\n",
    "The accuracy of $\\hat Y$ depends on **reducible** and **irreducible** errors. The error in prediction of $\\hat f$ is **reduible** and can be improved wth more data and better models. However, $\\hat Y$ is also a function of $\\epsilon$ which is **irreducible**. Thus, the best our predictions can get is \n",
    "\n",
    "$$\n",
    "\\hat Y = f(X)\n",
    "$$\n",
    "\n",
    "Focus of Statistical learning is to estimating $f$ as $\\hat f$ with least **reducible** error. However, the accuracy of $\\hat Y$ will always be controlled by **irreducible** and **unknown** error $\\epsilon$.\n",
    "\n",
    "In **prediction problems**, $\\hat f$ can be treated as **blackbox** as we are only interested in predicting $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "We are interested in understanding how each of the different $X_{1}... X_{p}$ affect the dependent variable $Y$, hence the name **inference**. Here, $f \\hat$ **cannot be treated as blackbox** and we need to know its exact form. Some questions that are sought to be answered through inference:\n",
    " - which predictor variables are associated with the response?\n",
    " - what is the relationship b/w response and each predictor?\n",
    " - is the relationship linear or is more complicated?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
